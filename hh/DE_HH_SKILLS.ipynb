{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека для работы с HTTP-запросами. Будем использовать ее для обращения к API HH\n",
    "import requests\n",
    " \n",
    "# Пакет для удобной работы с данными в формате json\n",
    "import json\n",
    " \n",
    "# Модуль для работы со значением времени\n",
    "import time\n",
    " \n",
    "# Модуль для работы с операционной системой. Будем использовать для работы с файлами\n",
    "import os\n",
    " \n",
    "  \n",
    "def getPage(page = 0):\n",
    "    \"\"\"\n",
    "    Создаем метод для получения страницы со списком вакансий.\n",
    "    Аргументы:\n",
    "        page - Индекс страницы, начинается с 0. Значение по умолчанию 0, т.е. первая страница\n",
    "    \"\"\"\n",
    "     \n",
    "    # Справочник для параметров GET-запроса\n",
    "    params = {\n",
    "        'text': '\"data engineer\"', # Текст фильтра. В имени должно быть слово \"Аналитик\"\n",
    "        'area': 113, # Поиск ощуществляется по вакансиям города Москва\n",
    "        'page': page, # Индекс страницы поиска на HH\n",
    "        'per_page': 100 # Кол-во вакансий на 1 странице\n",
    "    }\n",
    "     \n",
    "     \n",
    "    req = requests.get('https://api.hh.ru/vacancies', params) # Посылаем запрос к API\n",
    "    data = req.content.decode() # Декодируем его ответ, чтобы Кириллица отображалась корректно\n",
    "    req.close()\n",
    "    return data\n",
    " \n",
    " \n",
    "# Считываем первые 2000 вакансий\n",
    "for page in range(0, 20):\n",
    "     \n",
    "    # Преобразуем текст ответа запроса в справочник Python\n",
    "    jsObj = json.loads(getPage(page))\n",
    "     \n",
    "    # Сохраняем файлы в папку {путь до текущего документа со скриптом}\\docs\\pagination\n",
    "    # Определяем количество файлов в папке для сохранения документа с ответом запроса\n",
    "    # Полученное значение используем для формирования имени документа\n",
    "    nextFileName = './docs/pagination/{}.json'.format(len(os.listdir('./docs/pagination')))\n",
    "     \n",
    "    # Создаем новый документ, записываем в него ответ запроса, после закрываем\n",
    "    f = open(nextFileName, mode='w', encoding='utf8')\n",
    "    f.write(json.dumps(jsObj, ensure_ascii=False))\n",
    "    f.close()\n",
    "     \n",
    "    # Проверка на последнюю страницу, если вакансий меньше 2000\n",
    "    if (jsObj['pages'] - page) <= 1:\n",
    "        break\n",
    "     \n",
    "    # Необязательная задержка, но чтобы не нагружать сервисы hh, оставим. 5 сек мы может подождать\n",
    "    time.sleep(0.25)\n",
    "     \n",
    "print('Старницы поиска собраны')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    " \n",
    "# Получаем перечень ранее созданных файлов со списком вакансий и проходимся по нему в цикле \n",
    "for fl in os.listdir('./docs/pagination'):\n",
    "     \n",
    "    # Открываем файл, читаем его содержимое, закрываем файл\n",
    "    f = open('./docs/pagination/{}'.format(fl), encoding='utf8')\n",
    "    jsonText = f.read()\n",
    "    f.close()\n",
    "     \n",
    "    # Преобразуем полученный текст в объект справочника\n",
    "    jsonObj = json.loads(jsonText)\n",
    "     \n",
    "    # Получаем и проходимся по непосредственно списку вакансий\n",
    "    for v in jsonObj['items']:\n",
    "         \n",
    "        # Обращаемся к API и получаем детальную информацию по конкретной вакансии\n",
    "        req = requests.get(v['url'])\n",
    "        data = req.content.decode()\n",
    "        req.close()\n",
    "         \n",
    "        # Создаем файл в формате json с идентификатором вакансии в качестве названия\n",
    "        # Записываем в него ответ запроса и закрываем файл\n",
    "        fileName = './docs/vacancies/{}.json'.format(v['id'])\n",
    "        f = open(fileName, mode='w', encoding='utf8')\n",
    "        f.write(data)\n",
    "        f.close()\n",
    "         \n",
    "        time.sleep(0.25)\n",
    "         \n",
    "print('Вакансии собраны')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вакансии загружены в БД'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Библиотека для анализа данных, представляющая данные в табличном виде называемом DataFrame\n",
    "# Вся мощь данной библиотеки нам здесь не понадобиться, с ее помощью мы положим\n",
    "# данные в БД. Можно было бы написать простые insert-ы\n",
    "import pandas as pd\n",
    " \n",
    "import json\n",
    "import os\n",
    " \n",
    "# Библиотека для работы с СУБД\n",
    "from sqlalchemy import engine as sql\n",
    " \n",
    "# Модуль для работы с отображением вывода Jupyter\n",
    "from IPython import display\n",
    " \n",
    "# Создаем списки для столбцов таблицы vacancies\n",
    "IDs = [] # Список идентификаторов вакансий\n",
    "names = [] # Список наименований вакансий\n",
    "salaries = [] # Список зарплат вакансий\n",
    "descriptions = [] # Список описаний вакансий\n",
    " \n",
    "# Создаем списки для столбцов таблицы skills\n",
    "skills_vac = [] # Список идентификаторов вакансий\n",
    "skills_name = [] # Список названий навыков\n",
    "\n",
    "# Создаем списки для столбцов таблицы skills\n",
    "spec_vac = [] # Список идентификаторов вакансий\n",
    "spec_name = [] # Список названий specializations\n",
    " \n",
    "# В выводе будем отображать прогресс\n",
    "# Для этого узнаем общее количество файлов, которые надо обработать\n",
    "# Счетчик обработанных файлов установим в ноль\n",
    "cnt_docs = len(os.listdir('./docs/vacancies'))\n",
    "i = 0\n",
    " \n",
    "# Проходимся по всем файлам в папке vacancies\n",
    "for fl in os.listdir('./docs/vacancies'):\n",
    "     \n",
    "    # Открываем, читаем и закрываем файл\n",
    "    f = open('./docs/vacancies/{}'.format(fl), encoding='utf8')\n",
    "    jsonText = f.read()\n",
    "    f.close()\n",
    "     \n",
    "    # Текст файла переводим в справочник\n",
    "    jsonObj = json.loads(jsonText)\n",
    "     \n",
    "    # Заполняем списки для таблиц\n",
    "    IDs.append(jsonObj['id'])\n",
    "    names.append(jsonObj['name'])\n",
    "    salaries.append(jsonObj['salary'])\n",
    "    descriptions.append(jsonObj['description'])\n",
    "     \n",
    "    # Т.к. навыки хранятся в виде массива, то проходимся по нему циклом\n",
    "    for skl in jsonObj['key_skills']:\n",
    "        skills_vac.append(jsonObj['id'])\n",
    "        skills_name.append(skl['name'])\n",
    "        \n",
    "    # Т.к. специализации хранятся в виде массива, то проходимся по нему циклом\n",
    "    for skl in jsonObj['specializations']:\n",
    "        spec_vac.append(jsonObj['id'])\n",
    "        spec_name.append(skl['name'])\n",
    "     \n",
    "    # Увеличиваем счетчик обработанных файлов на 1, очищаем вывод ячейки и выводим прогресс\n",
    "    i += 1\n",
    "    display.clear_output(wait=True)\n",
    "    display.display('Готово {} из {}'.format(i, cnt_docs))\n",
    " \n",
    " \n",
    "# Создадим соединение с БД\n",
    "eng = sql.create_engine('postgresql://postgres:1234@localhost:5432/postgres')\n",
    "conn = eng.connect()\n",
    " \n",
    "# Создаем пандосовский датафрейм, который затем сохраняем в БД в таблицу vacancies\n",
    "df = pd.DataFrame({'id': IDs, 'name': names, 'salary': salaries, 'description': descriptions})\n",
    "df['salary'] = list(map(lambda x: json.dumps(x), df['salary']))\n",
    "df.to_sql('vacancies', conn, schema='public', if_exists='append', index=False)\n",
    " \n",
    "# Тоже самое, но для таблицы skills\n",
    "df = pd.DataFrame({'vacancy': skills_vac, 'skill': skills_name})\n",
    "df.to_sql('skills', conn, schema='public', if_exists='append', index=False)\n",
    "\n",
    "# Тоже самое, но для таблицы skills\n",
    "df = pd.DataFrame({'vacancy': spec_vac, 'profarea_name': spec_name})\n",
    "df.to_sql('specializations', conn, schema='public', if_exists='append', index=False)\n",
    " \n",
    "# Закрываем соединение с БД\n",
    "conn.close()\n",
    " \n",
    "# Выводим сообщение об окончании программы\n",
    "display.clear_output(wait=True)\n",
    "display.display('Вакансии загружены в БД')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "conn = sqlalchemy.create_engine('postgresql://postgres:1234@localhost:5432/postgres').connect()\n",
    " \n",
    "import pandas as pd\n",
    " \n",
    "# Загружаем наименования вакансий\n",
    "sql = 'select name from public.vacancies'   \n",
    "vacancies_name = pd.read_sql(sql, conn).name\n",
    " \n",
    "# Загружаем навыки по вакансиям\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        v.name,\n",
    "        skill\n",
    "    from\n",
    "        public.skills s\n",
    "        join public.vacancies v\n",
    "            on v.id = s.vacancy\n",
    "\"\"\"\n",
    " \n",
    "skills = pd.read_sql(sql, conn)\n",
    " \n",
    "# Закрываем соединение с БД\n",
    "conn.close()\n",
    " \n",
    "# sklearn - библиотека, содержащая набор инструментов для машинного обучения.\n",
    "# feature_extraction.text извлекает признаки из текста, которые затем можно будет \n",
    "# использовать в моделировании. В нашем случае моделирование не требуется. Нам нужно \n",
    "# получить биграммы и их оценку\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    " \n",
    "# Получим матрицу встрчаемости биграмм (токенов) для каждой вакансии\n",
    "# В качестве стоп-слов установим грейды сотрудников, т.е. нам \n",
    "# не важно Старший аналитик данных или Младший, нам важно, что он аналитик данных\n",
    "# Также исключаем биграммы, которые встречаются реже, чем в 1-ой тысячной всех вакансий\n",
    "cv=CountVectorizer(\n",
    "    ngram_range=(2,2), \n",
    "    stop_words=['ведущий', 'главный', 'младший', 'эксперт', 'стажер', 'старший', \n",
    "                'middle', 'junior', 'senior'],\n",
    "    min_df=0.001\n",
    ")\n",
    "word_vector=cv.fit_transform(vacancies_name)\n",
    " \n",
    "# Рассчитаем меру idf (обратная частота документа)\n",
    "# Чем выше мера для конкретного токена, тем реже он встречается\n",
    "idf = TfidfTransformer().fit(word_vector)\n",
    " \n",
    "# Строим датафрейм с оценкой idf для каждого токена. Далее он понадобится для построения облака \n",
    "df_idf = pd.DataFrame(idf.idf_, index=cv.get_feature_names(), columns=[\"idf\"])\n",
    " \n",
    "# Строим датафрейм из матрицы частоты токенов, где в качестве строк вакансии,\n",
    "# токены в качестве столбцов. Далее используем его для получения списка вакансий, для\n",
    "# которых встречается конкретный токен\n",
    "pivot = pd.DataFrame(\n",
    "            word_vector.toarray(), \n",
    "            columns=cv.get_feature_names(), \n",
    "            index=vacancies_name.values\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    function tag_click(e){\n",
       "        var kernel = Jupyter.notebook.kernel\n",
       "        func = 'get_detail(\"' + e.innerText + '\")'\n",
       "        kernel.execute(func)\n",
       "    }\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac02f4b780a4951ad59fc995b77461c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e0d7d59a3d42229fec3b411a06911c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(Output(layout=Layout(grid_area='center')),), layout=Layout(grid_template_areas='\"center ce…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Импортируем виджеты. Они позволяют более гибко управлять выводом jupyter и \n",
    "# создавать интерактивные элементы\n",
    "import ipywidgets as widget\n",
    " \n",
    "# Импортируем модуль вывода jupyter\n",
    "from IPython import display\n",
    " \n",
    "# Библиотека для визуализации данных\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Модуль математических функций\n",
    "import math\n",
    " \n",
    "################################################\n",
    " \n",
    "def click_back(b):\n",
    "    \"\"\"\n",
    "       Метод, который вызывается при клике на кнопку \"Назад\".\n",
    "       Метод скрывает информацию о перечне вакансий из левого сайдбара и\n",
    "       диаграмму популярности навыков из правого сайдбара, а также отображает\n",
    "       в центральной части шаблона облако токенов.\n",
    "    \"\"\"\n",
    "    app_layout.left_sidebar = None\n",
    "    app_layout.right_sidebar = None\n",
    "    app_layout.center = out_words\n",
    " \n",
    "################################################\n",
    " \n",
    "def print_words(x):\n",
    "    \"\"\"\n",
    "        Метод, который вызывается при изменении значения слайдера.\n",
    "        Метод отрисовывает в формате html облако токенов\n",
    "         \n",
    "        Аргумент \"x\" принимает справочник, который содержит состояние слайдера. Используем\n",
    "        x.new, чтобы получить новое состояние слайдера.\n",
    "    \"\"\"\n",
    "     \n",
    "    # Получаем датафрейм, отсортированный в обратном порядке по мере idf, \n",
    "    # ограниченный диапазоном значений, заданным слайдером\n",
    "    ds = df_idf.sort_values(by='idf', ascending=False)[x.new[0]: x.new[1]]\n",
    "     \n",
    "    # Получаем максимальное и минимальное значения idf. Будем использовать их для установки\n",
    "    # размера шрифта токена в облаке\n",
    "    mx = df_idf['idf'].max()\n",
    "    mn = df_idf['idf'].min()\n",
    "     \n",
    "    # Задаем общие css-стили для облака токенов\n",
    "    tags = \"\"\"<style>\n",
    "    .tagword{\n",
    "        border:1px solid #bee5eb;\n",
    "        padding:1px 5px;\n",
    "        display:block;\n",
    "        border-radius:4px;\n",
    "        color:#0c5460;\n",
    "        background:#d1ecf1;\n",
    "        line-height:normal;\n",
    "        cursor:pointer}\n",
    "    .tagword:hover{\n",
    "        background:#c1dce1}\n",
    "    .tag-wrapper{\n",
    "        float:left;\n",
    "        margin:0 5px 5px 0}\n",
    "    </style>\"\"\"\n",
    "     \n",
    "    # Пробегаемся по токенам, выбранным с помощью слайдера\n",
    "    for r in ds.sort_index().itertuples():\n",
    "         \n",
    "        # Масштабируем значения idf от 0 до 1 и переворачиваем их, \n",
    "        # чтобы максимальное значение стало минимальным.\n",
    "        if mx > mn:\n",
    "             \n",
    "            # Задаем размер шрифта и высоту токена в облаке\n",
    "            fs = int( (((r.idf - mn) / (mx - mn)) * -1 + 1 ) * 30 + 10 )\n",
    "            hd = math.ceil(fs / 10) * 10 + 8\n",
    "        else:\n",
    "            fs = 40\n",
    "         \n",
    "        # Добавляем токен в облако в формате html. Токену назначаем функцию tag_click для\n",
    "        # события клика. Сама функция описана ниже за пределами данного метода\n",
    "        tag_tmpl = \"\"\"<div class=\"tag-wrapper\" style=\"height:{height}px\">\n",
    "            <span onclick=\"tag_click(this)\" class=\"tagword\" style=\"font-size:{size}px\">{name}</span>\n",
    "        </div>\"\"\"\n",
    "        tags += tag_tmpl.format(name=r.Index, size=fs, height=hd)\n",
    "     \n",
    "    # Отрисовываем облако токенов \n",
    "    click_back(None)\n",
    "    out_words.clear_output(wait=True)\n",
    "    with out_words:\n",
    "        display.display_html(tags, raw=True)\n",
    "         \n",
    "################################################\n",
    "         \n",
    "def get_detail(w):\n",
    "    \"\"\"\n",
    "        Метод отрисовывает детелизацию по токену, а именно перечень вакансий, \n",
    "        содержащих переданный токен, и топ-20 самых востребованных навыков по этим вакансиям.\n",
    "         \n",
    "        Аргумент \"w\" принимает значение токена, по которому кликнули\n",
    "    \"\"\"\n",
    "     \n",
    "    # Выводим пандосовский датафрейм со списком вакансий, содержащих токен\n",
    "    out_details_vac.clear_output(wait=True)\n",
    "    vacs = pivot[pivot[w] > 0].sort_index().index.unique()\n",
    "    with out_details_vac:\n",
    "        display.display_html(\n",
    "                pd.DataFrame(data=vacs, columns=['Список вакансий:']).to_html(index=False), raw=True\n",
    "        )\n",
    "     \n",
    "    # Выводим горизонтальный столбчатый график самых популярных навыков по выбранным вакансиям\n",
    "    out_details_skl.clear_output(wait=True)\n",
    "    skill_pvt = skills \\\n",
    "                .query('name in @vacs') \\\n",
    "                .groupby(by='skill', as_index=False) \\\n",
    "                .agg({'name':'count'}) \\\n",
    "                .sort_values(by='name', ascending=False).head(20)\n",
    "    fig_h = skill_pvt.shape[0] / 2.5    # Корректируем размер графика на \n",
    "                                        # основании количества получившихся столбцов\n",
    "    with out_details_skl:\n",
    "        skill_pvt.sort_values(by='name').plot.barh(\n",
    "                        x='skill', \n",
    "                        y='name', \n",
    "                        figsize=(5, fig_h), \n",
    "                        legend=None, \n",
    "                        title='ТОП20 Навыков'\n",
    "        )\n",
    "        plt.show()\n",
    "     \n",
    "     \n",
    "    # Скрываем облако токенов и выводим детализацию для токена\n",
    "    app_layout.center = None\n",
    "    app_layout.left_sidebar = out_details_vac\n",
    "    app_layout.right_sidebar = out_details_skl\n",
    " \n",
    "################################################\n",
    " \n",
    "# Создаем несколько виджетов вывода\n",
    "out_header = widget.Output() # Сюда будем выводить виджет слайдера и кнопку возврата\n",
    "out_words = widget.Output() # Сюда будем выводить облако\n",
    "out_details_vac = widget.Output() # Сюда будем выводить перечень вакансий, содержащих токен\n",
    "out_details_skl = widget.Output() # Сюда будем выводить график навыков по вакансиям, содержащим токен\n",
    " \n",
    "# Создаем виджет макета. Весь отчет по сути располагается в данном макете.\n",
    "# Пока только с выводом в центр виджета с облаком\n",
    "app_layout = widget.AppLayout(\n",
    "    header=None,\n",
    "    left_sidebar=None,\n",
    "    center=out_words,\n",
    "    right_sidebar=None,\n",
    "    footer=None,\n",
    "    pane_heights=[1, 5, '60px']\n",
    ")\n",
    " \n",
    "# Создаем виджет слайдера, для указания диапазона рассматриваемых токенов\n",
    "sld = widget.IntRangeSlider(\n",
    "    value=[0, 0],\n",
    "    min=0,\n",
    "    max=df_idf['idf'].count(),\n",
    "    step=1,\n",
    "    description='Частота:',\n",
    "    layout = {'width': '100%'}\n",
    ")\n",
    "# Назначаем слайдеру метод, который будет вызываться при изменении значения слайдера\n",
    "sld.observe(print_words, names='value')\n",
    " \n",
    "# Создаем виджет кнопки\n",
    "bck_btn = widget.Button(\n",
    "    description='Назад',\n",
    "    button_style='info'\n",
    ")\n",
    "# Назначаем кнопке метод, который будет вызываться по событию клика по ней\n",
    "bck_btn.on_click(click_back)\n",
    " \n",
    "# В формате html подготовим строку, которая создаст функцию на языке javascript\n",
    "# Данную функцию будем вызывать по событию клика по токену в облаке\n",
    "html = \"\"\"\n",
    "<script>\n",
    "    function tag_click(e){\n",
    "        var kernel = Jupyter.notebook.kernel\n",
    "        func = 'get_detail(\"' + e.innerText + '\")'\n",
    "        kernel.execute(func)\n",
    "    }\n",
    "</script>\"\"\"\n",
    " \n",
    "# Выводим в виджет вывода виджеты слайдера и кнопки\n",
    "with out_header:\n",
    "    display.display(sld)\n",
    "    display.display(bck_btn)\n",
    " \n",
    "display.display_html(html, raw=True) # Отображаем в ячейке ранее подготовленный html c js-функцией\n",
    "display.display(out_header) # Отображаем виджет, содержащий слайдер и кнопку\n",
    "display.display(app_layout) # Отображаем виджет макета\n",
    " \n",
    "# Задаем новые значения диапазона слайдера, чтобы отобразить ТОП-30 самых популярных токенов\n",
    "# Данная строка спровоцирует изменения, что в свою очередь вызовет установленный метод print_words,\n",
    "# который формирует облако\n",
    "sld.value = [sld.max - 30, sld.max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
